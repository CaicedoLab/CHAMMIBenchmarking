{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import skimage\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import folded_dataset\n",
    "reload(folded_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bd660-6e62-44f6-a2f4-60a6a5dae62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code\n",
    "\n",
    "# root_dir = '/scr/zchen/datasets/CHAMMI'\n",
    "\n",
    "# dataset_name = 'CP'\n",
    "# df_path = f'{root_dir}/{dataset_name}/enriched_meta.csv'\n",
    "# df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to add your own path to the images\n",
    "#root_dir = '/scr/zchen/datasets/morphem_70k_2.0/'\n",
    "root_dir = '/scr/nnair/dataset/CHAMMI'\n",
    "feature_dir = '/scr/nnair/all_features'\n",
    "\n",
    "\n",
    "# why is dataset name only CP (this variable is not changed anywhere else)\n",
    "#dataset_name = 'CP'\n",
    "# dataset_names = ['CP', 'Allen', 'HPA']\n",
    "# index = 0\n",
    "# dataset_name = pick_dataset(dataset_names, index)\n",
    "# df_path = f'{root_dir}{dataset_name}/enriched_meta.csv'\n",
    "# df = pd.read_csv(df_path)\n",
    "\n",
    "# def pick_dataset(dataset_names, index):\n",
    "#     dataset_name = dataset_names[index]\n",
    "#     index++;\n",
    "#     return dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = folded_dataset.SingleCellDataset(csv_file=df_path,\n",
    "#                                            root_dir=root_dir, target_labels='train_test_split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_inds = [0, 100, 200]\n",
    "# for ind in sample_inds:\n",
    "#     fig, axes = plt.subplots(1,2,figsize=(10,5))\n",
    "#     axes[0].imshow(io.imread(root_dir + df.iloc[ind].file_path))\n",
    "#     axes[1].imshow(dataset[ind][0].numpy().transpose(1,2,0)[:,:,:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb0a2f-a1ac-45db-ab38-493885fcdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_dataset(root_dir, dataset_name):\n",
    "    df_path = f'{root_dir}/{dataset_name}/enriched_meta.csv'\n",
    "    df = pd.read_csv(df_path)\n",
    "    dataset = folded_dataset.SingleCellDataset(csv_file=df_path, root_dir=root_dir, target_labels='train_test_split')\n",
    "    sample_inds = [0, 100, 200]\n",
    "    for ind in sample_inds:\n",
    "        fig, axes = plt.subplots(1,2,figsize=(10,5))\n",
    "        axes[0].imshow(io.imread(root_dir + df.iloc[ind].file_path))\n",
    "        axes[1].imshow(dataset[ind][0].numpy().transpose(1,2,0)[:,:,:3])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000e728-a0b5-4127-befb-1a3ce4321832",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convnext Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f90f0-84c6-40dd-9af8-8ee29e11ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm import create_model\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9673ab7-c4b9-4727-ba1c-55df82b9e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(pooling='avg', x: torch.Tensor) -> torch.Tensor:\n",
    "    x = feature_extractor(x)\n",
    "    if pooling == 'avg':\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "    elif pooling == 'max':\n",
    "        x = F.adaptive_max_pool2d(x, (1, 1))\n",
    "    elif pooling == 'avg_max':\n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x = torch.cat([x_avg, x_max], dim=1)\n",
    "    elif pooling == None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Pooling {self.cfg.pooling} not supported. Use one of {FeaturePooling.list()}\"\n",
    "        )\n",
    "    # x = rearrange(x, \"b c h w -> b (c h w)\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff512b-d9db-421e-9057-93e241e222aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bced0f-5720-4cca-ba32-323a7e21d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am confused by this because I do not see a directory called \"features\"\n",
    "#feature_dir = f'{root_dir}features'\n",
    "feature_file = 'pretrained_convnext_channel_replicate.npy'\n",
    "# pooling = 'avg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db255dc9-dee5-4ece-84b6-293ad7489e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = True\n",
    "model = create_model(\"convnext_tiny.fb_in22k\", pretrained=pretrained).to(device)\n",
    "feature_extractor = nn.Sequential(\n",
    "                    model.stem,\n",
    "                    model.stages[0],\n",
    "                    model.stages[1],\n",
    "                    model.stages[2].downsample,\n",
    "                    *[model.stages[2].blocks[i] for i in range(9)],\n",
    "                    model.stages[3].downsample,\n",
    "                    *[model.stages[3].blocks[i] for i in range(3)],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938c58a-a0db-4c3a-99dc-e1d2bed61b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_save_features(model, feature_dir, feature_file, root_dir)\n",
    "# train_dataloader = DataLoader(dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618c821-2135-44cc-b953-221bfc2e7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feat = []\n",
    "# for images, label in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "#     cloned_images = images.clone()\n",
    "#     batch_feat = []\n",
    "#     for i in range(cloned_images.shape[1]):\n",
    "#         # Copy each channel three times \n",
    "#         channel = cloned_images[:, i, :, :]\n",
    "#         channel = channel.unsqueeze(1)\n",
    "#         expanded = channel.expand(-1, 3, -1, -1).to(device)\n",
    "\n",
    "#         # feat_temp = m.forward_features(expanded).cpu().detach().numpy()\n",
    "#         feat_temp = forward(expanded).cpu().detach().numpy()\n",
    "#         batch_feat.append(feat_temp)\n",
    "        \n",
    "#     batch_feat = np.concatenate(batch_feat, axis=1)\n",
    "#     all_feat.append(batch_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb84e7-c220-446a-9c87-690698d839aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feat = np.concatenate(all_feat)\n",
    "# all_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a785a3-4945-4d3b-b5c8-24f7021b2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feat = all_feat.squeeze(2).squeeze(2)\n",
    "# all_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49dd5f-e01b-48f1-b64d-9cf187a9d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_path = f'{feature_dir}/{dataset_name}/{feature_file}'\n",
    "# np.save(feature_path, all_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84e015",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ResNet Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d19fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same issue regarding \"features\" directory\n",
    "# feature_dir = f'{root_dir}features'\n",
    "feature_file = 'pretrained_resnet18_features.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34397e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "m = resnet18(weights=weights).to(device)\n",
    "feature_extractor = torch.nn.Sequential(*list(m.children())[:-1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b992bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_save_features(m, feature_dir, feature_file, root_dir)\n",
    "# train_dataloader = DataLoader(dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess = weights.transforms()\n",
    "# all_feat = []\n",
    "# for images, label in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "#     cloned_images = images.clone()\n",
    "#     batch_feat = []\n",
    "#     for i in range(cloned_images.shape[1]):\n",
    "#         # Copy each channel three times \n",
    "#         channel = cloned_images[:, i, :, :]\n",
    "#         channel = channel.unsqueeze(1)\n",
    "#         expanded = channel.expand(-1, 3, -1, -1)\n",
    "\n",
    "#         expanded = preprocess(expanded).to(device)\n",
    "#         feat_temp = feature_extractor(expanded).cpu().detach().numpy()\n",
    "#         batch_feat.append(feat_temp)\n",
    "#     batch_feat = np.concatenate(batch_feat, axis=1)\n",
    "#     all_feat.append(batch_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12406d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feat = np.concatenate(all_feat)\n",
    "# all_feat = all_feat.squeeze(2).squeeze(2)\n",
    "# all_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c83987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why not use feature_dir and feature_file here?\n",
    "# feature_path = f'{root_dir}features/{dataset_name}/pretrained_resnet18_features.npy'\n",
    "# np.save(feature_path, all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74184c-95bd-4fcb-b73a-34735434bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_features(model, feature_dir, feature_file, root_dir):\n",
    "    dataset_names = ['CP', 'Allen', 'HPA']\n",
    "    for dataset in dataset_names:\n",
    "        dataset = configure_dataset(root_dir, dataset)\n",
    "        train_dataloader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "        preprocess = weights.transforms()\n",
    "        all_feat = []\n",
    "        for images, label in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "            cloned_images = images.clone()\n",
    "            batch_feat = []\n",
    "            for i in range(cloned_images.shape[1]):\n",
    "                # Copy each channel three times \n",
    "                channel = cloned_images[:, i, :, :]\n",
    "                channel = channel.unsqueeze(1)\n",
    "                expanded = channel.expand(-1, 3, -1, -1).to(device)\n",
    "        \n",
    "                if type(model) == models.resnet.ResNet:\n",
    "                    expanded = preprocess(expanded).to(device)\n",
    "                    feat_temp = feature_extractor(expanded).cpu().detach().numpy()\n",
    "                else: \n",
    "                    feat_temp = forward(expanded).cpu().detach().numpy()\n",
    "                    \n",
    "                batch_feat.append(feat_temp)\n",
    "                \n",
    "            batch_feat = np.concatenate(batch_feat, axis=1)\n",
    "            all_feat.append(batch_feat)\n",
    "       \n",
    "        all_feat = np.concatenate(all_feat)\n",
    "        all_feat = all_feat.squeeze(2).squeeze(2)\n",
    "        feature_path = feature_path = f'{feature_dir}/{dataset}/{feature_file}'\n",
    "        np.save(feature_path, all_feat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
